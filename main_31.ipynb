{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually implement CNN for CIFAR-10 dataset\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transform to normalize the data and augment it\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 20\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data/\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data/\", train=False, transform=transform\n",
    ")\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network with following layers:\n",
    "# CONV1: with Kernel size (3 ×3), In channels 3, Out channels 32.\n",
    "# POOL1: Kernel size (2 ×2).\n",
    "# CONV2: Kernel size (5 ×5), In channels 32, Out channels 64\n",
    "# POOL2: Kernel size (2 ×2).\n",
    "# CONV3: Kernel size (3 ×3), In channels 64, Out channels 64.\n",
    "# FC1: Fully connected layer (also known as Linear layer) with 64 output neurons.\n",
    "# FC2: Fully connected layer with 10 output neurons.\n",
    "# Use ReLU as the activation function for all layers apart from the max-pooling layers, and the FC2layer. \n",
    "# You need to flatten the CONV3 output before passing as input to FC1. \n",
    "# Implement the forward and the backward passes. \n",
    "# Complete the code for the Conv2D, MaxPool2D, Linear, and ReLU layers and use these to implement the network.\n",
    "# Complete the training code, \n",
    "# and train for 20 epochs using an Adam optimizer with learning rate 0.001 and batch size 32. \n",
    "# Use the categorical cross entropy loss as the loss function\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(out_channels))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add padding to the input tensor\n",
    "        x = F.pad(x, (self.padding, self.padding, self.padding, self.padding))\n",
    "        \n",
    "        # Unfold the input tensor and reshape it\n",
    "        x_unfolded = F.unfold(x, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        x_unfolded = x_unfolded.view(x.shape[0], self.in_channels, self.kernel_size, self.kernel_size, -1)\n",
    "        \n",
    "        # Perform the convolution using einsum\n",
    "        x_conv = torch.einsum('nchwv, ochw -> nocv', x_unfolded, self.weight)\n",
    "        \n",
    "        # Add the bias and reshape the output tensor\n",
    "        _, _, output_h, output_w = F.conv2d_input_size(x.shape, self.weight.shape, self.stride, self.padding)\n",
    "        x_conv = x_conv.sum(dim=1).view(x.shape[0], self.out_channels, output_h, output_w)\n",
    "        x_conv += self.bias.view(1, self.out_channels, 1, 1)\n",
    "        \n",
    "        return x_conv\n",
    "\n",
    "class MaxPool2D(nn.Module):\n",
    "    def __init__(self, kernel_size, stride=None, padding=0):\n",
    "        super(MaxPool2D, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride if stride is not None else kernel_size\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement the forward pass\n",
    "        x = F.pad(x, (self.padding, self.padding, self.padding, self.padding))\n",
    "        x_unfolded = F.unfold(x, kernel_size=self.kernel_size, stride=self.stride)\n",
    "        x_unfolded = x_unfolded.view(x.shape[0], x.shape[1], self.kernel_size * self.kernel_size, -1)\n",
    "        x = torch.max(x_unfolded, dim=2)[0]\n",
    "        output_h, output_w = F.conv2d_output_size(x.shape[2:], (self.kernel_size, self.kernel_size), self.stride, self.padding)\n",
    "        x = x.view(x.shape[0], x.shape[1], output_h, output_w)\n",
    "        return x\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Implement the forward pass\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = torch.einsum('ni, io -> no', x, self.weight)\n",
    "        x = x + self.bias.unsqueeze(0)\n",
    "        return x\n",
    "    \n",
    "class ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Implement the forward pass\n",
    "        x = torch.max(x, torch.zeros_like(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = Conv2D(3, 32, 3, 1, 1)\n",
    "        self.pool1 = MaxPool2D(2, 2)\n",
    "        self.conv2 = Conv2D(32, 64, 5, 1, 2)\n",
    "        self.pool2 = MaxPool2D(2, 2)\n",
    "        self.conv3 = Conv2D(64, 64, 3, 1, 1)\n",
    "        self.fc1 = Linear(64, 64)\n",
    "        self.fc2 = Linear(64, num_classes)\n",
    "        self.relu = ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Implement the forward pass\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loss and accuracy tracking\n",
    "epoch_train_loss = []\n",
    "epoch_val_loss = []\n",
    "epoch_val_acc = []\n",
    "\n",
    "# Now, train the model for 20 epochs\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Run the forward pass\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        \n",
    "    # Evaluate the model on the validation set\n",
    "    running_val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    epoch_val_loss = running_val_loss / len(test_loader)\n",
    "    epoch_val_acc = val_correct / float(val_total)\n",
    "\n",
    "    # Print the loss for every epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {epoch_train_loss[-1]:.4f}, Validation loss: {epoch_val_loss[-1]:.4f}, Validation accuracy: {epoch_val_acc[-1]:.2f}%')\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), epoch_train_loss, label=\"Training Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), epoch_val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot the epoch vs. overall validation accuracy\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), epoch_val_acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy (%)')\n",
    "plt.title('Epoch vs. Overall Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model for class-wise accuracy\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Class-wise accuracy\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    for images, labels in test_loader:\n",
    "        # Run the forward pass\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # Get the predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Collect the correct predictions for each class\n",
    "        c = (predicted == labels)\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "    \n",
    "    # Print the accuracy for each class\n",
    "    for i in range(num_classes):\n",
    "        print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
